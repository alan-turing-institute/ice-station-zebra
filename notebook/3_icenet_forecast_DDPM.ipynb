{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "PyTorch UNet implementation using IceNet library for data download and post-processing of sea ice forecasting.\n",
    "\n",
    "This notebook has been designed to be independent of other notebooks.\n",
    "\n",
    "### Highlights\n",
    "The key features of this notebook are:\n",
    "* [1. Download](#1.-Download) \n",
    "* [2. Data Processing](#2.-Data-Processing)\n",
    "* [3. Train](#3.-Train)\n",
    "* [4. Prediction](#4.-Prediction)\n",
    "* [5. Outputs and Plotting](#5.-Outputs-and-Plotting)\n",
    "\n",
    "Please note that this notebook relies on a pytorch data loader implementation which is only available from icenet v0.2.8+.\n",
    "\n",
    "To install the necessary python packages, you can use the conda `icenet-notebooks/pytorch/environment.yml` environment file on a Linux system to be able to set-up the necessary pytorch + tensorflow + CUDA + other modules which could be a tricky mix to get working manually:\n",
    "\n",
    "```bash\n",
    "conda env create -f environment.yml\n",
    "```\n",
    "\n",
    "### Contributions\n",
    "#### PyTorch implementation of UnetDiffusion\n",
    "Maria Carolina Novitasari\n",
    "\n",
    "#### PyTorch implementation of IceNet\n",
    "\n",
    "Andrew McDonald ([icenet-gan](https://github.com/ampersandmcd/icenet-gan))\n",
    "\n",
    "Bryn Noel Ubald (Refactor, updates for daily predictions and matching icenet library)\n",
    "\n",
    "#### Notebook\n",
    "Bryn Noel Ubald (author)\n",
    "\n",
    "#### PyTorch Integration\n",
    "Bryn Noel Ubald\n",
    "\n",
    "Ryan Chan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Download Daily Data for IceNet\n",
    "\n",
    "#### DOWNLOAD SIC Data  \n",
    "\n",
    "To download Sea Ice Concentration (SIC) data, modify the script below with the desired date range:\n",
    "\n",
    "```python\n",
    "sic = SICDownloader(\n",
    "    dates=[\n",
    "        pd.to_datetime(date).date()  # Dates to download SIC data for\n",
    "        for date in pd.date_range(\"2020-01-01\", \"2020-12-31\", freq=\"D\")\n",
    "    ],\n",
    "    delete_tempfiles=True,           # Delete temporary downloaded files after use\n",
    "    north=False,                     # Use mask for the Northern Hemisphere (set to True if needed)\n",
    "    south=True,                      # Use mask for the Southern Hemisphere\n",
    "    parallel_opens=True,             # Enable parallel processing with dask.delayed\n",
    ")\n",
    "\n",
    "sic.download()\n",
    "```\n",
    "\n",
    "#### Download ERA5 Data  \n",
    "\n",
    "##### Setup ERA5 API\n",
    "\n",
    "Use the following link to set up the ERA5 API: [https://cds.climate.copernicus.eu/how-to-api?](https://cds.climate.copernicus.eu/how-to-api?).\n",
    "\n",
    "Run the following script with your desired dates:\n",
    "\n",
    "#### ERA5 Downloader  \n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from icenet.data.interfaces.cds import ERA5Downloader\n",
    "\n",
    "era5 = ERA5Downloader(\n",
    "    var_names=[\"tas\", \"zg\", \"uas\", \"vas\"],      # Name of variables to download\n",
    "    dates=[                                     # Dates to download the variable data for\n",
    "        pd.to_datetime(date).date()\n",
    "        for date in pd.date_range(\"2020-01-01\", \"2020-12-31\", freq=\"D\")\n",
    "    ],\n",
    "    path=\"./data\",                              # Location to download data to (default is `./data`)\n",
    "    delete_tempfiles=True,                      # Whether to delete temporary downloaded files\n",
    "    levels=[None, [250, 500], None, None],      # The levels at which to obtain the variables for (e.g. for zg, it is the pressure levels)\n",
    "    max_threads=4,                              # Maximum number of concurrent downloads\n",
    "    north=False,                                # Boolean: Whether require data across northern hemisphere\n",
    "    south=True,                                 # Boolean: Whether require data across southern hemisphere\n",
    "    use_toolbox=False)                          # Experimental, alternative download method\n",
    "\n",
    "era5.download()                                 # Start downloading\n",
    "```\n",
    "\n",
    "The prototype data currently in use (South Pole, 2020) can be downloaded from **Baskerville** at the following path: `/vjgo8416-ice-frcst/shared/prototype_data/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from typing import Tuple\n",
    "from torchmetrics import Metric\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.utilities.types import TRAIN_DATALOADERS\n",
    "from torchmetrics import MetricCollection\n",
    "\n",
    "# We also set the logging level so that we get some feedback from the API\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import sys\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "sys.stdout = open(f'training_log_{timestamp}.txt', 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from icenet.data.sic.mask import Masks\n",
    "from icenet.data.interfaces.cds import ERA5Downloader\n",
    "from icenet.data.sic.osisaf import SICDownloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unset SLURM_NTASKS if it's causing issues\n",
    "if \"SLURM_NTASKS\" in os.environ:\n",
    "    del os.environ[\"SLURM_NTASKS\"]\n",
    "\n",
    "# Optionally, set SLURM_NTASKS_PER_NODE if needed\n",
    "os.environ[\"SLURM_NTASKS_PER_NODE\"] = \"1\"  # or whatever value is appropriate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask data\n",
    "\n",
    "Create masks for masking data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = Masks(north=False, south=True)\n",
    "masks.generate(save_polarhole_masks=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Climate and Sea Ice data\n",
    "\n",
    "Download climate variables from ERA5 and sea ice concentration from OSI-SAF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "era5 = ERA5Downloader(\n",
    "    var_names=[\"tas\", \"zg\", \"uas\", \"vas\"],\n",
    "    levels=[None, [250, 500], None, None],\n",
    "    dates=[pd.to_datetime(date).date() for date in\n",
    "           pd.date_range(\"2020-01-01\", \"2020-04-30\", freq=\"D\")],\n",
    "    delete_tempfiles=False,\n",
    "    max_threads=64,\n",
    "    north=False,\n",
    "    south=True,\n",
    "    # NOTE: there appears to be a bug with the toolbox API at present (icenet#54)\n",
    "    use_toolbox=False\n",
    ")\n",
    "\n",
    "# era5.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sic = SICDownloader(\n",
    "    dates=[pd.to_datetime(date).date() for date in\n",
    "           pd.date_range(\"2020-01-01\", \"2020-04-30\", freq=\"D\")],\n",
    "    delete_tempfiles=False,\n",
    "    north=False,\n",
    "    south=True,\n",
    "    parallel_opens=False,\n",
    ")\n",
    "\n",
    "# sic.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-grid ERA5 reanalysis data, and rotate wind vector data from ERA5 to align with EASE2 projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "era5.regrid()\n",
    "era5.rotate_wind_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Processing\n",
    "\n",
    "Process downloaded datasets.\n",
    "\n",
    "To make life easier, setting up train, val, test dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_dates = dict(\n",
    "    train=[pd.to_datetime(el) for el in pd.date_range(\"2020-01-01\", \"2020-03-31\")],\n",
    "    val=[pd.to_datetime(el) for el in pd.date_range(\"2020-04-03\", \"2020-04-23\")],\n",
    "    test=[pd.to_datetime(el) for el in pd.date_range(\"2020-04-01\", \"2020-04-02\")],\n",
    ")\n",
    "processed_name = \"notebook_api_pytorch_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create the data producer and configure them for the dataset we want to create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icenet.data.processors.era5 import IceNetERA5PreProcessor\n",
    "from icenet.data.processors.meta import IceNetMetaPreProcessor\n",
    "from icenet.data.processors.osi import IceNetOSIPreProcessor\n",
    "\n",
    "pp = IceNetERA5PreProcessor(\n",
    "    [\"uas\", \"vas\"],\n",
    "    [\"tas\", \"zg500\", \"zg250\"],\n",
    "    processed_name,\n",
    "    processing_dates[\"train\"],\n",
    "    processing_dates[\"val\"],\n",
    "    processing_dates[\"test\"],\n",
    "    linear_trends=tuple(),\n",
    "    north=False,\n",
    "    south=True\n",
    ")\n",
    "\n",
    "osi = IceNetOSIPreProcessor(\n",
    "    [\"siconca\"],\n",
    "    [],\n",
    "    processed_name,\n",
    "    processing_dates[\"train\"],\n",
    "    processing_dates[\"val\"],\n",
    "    processing_dates[\"test\"],\n",
    "    linear_trends=tuple(),\n",
    "    north=False,\n",
    "    south=True\n",
    ")\n",
    "\n",
    "meta = IceNetMetaPreProcessor(\n",
    "    processed_name,\n",
    "    north=False,\n",
    "    south=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we initialise the data processors using `init_source_data` which scans the data source directories to understand what data is available for processing based on the parameters. Since we named the processed data `\"notebook_api_data\"` above, it will create a data loader config file, `loader.notebook_api_data.json`, in the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Causes hanging on training, when generating sample.\n",
    "pp.init_source_data(\n",
    "    lag_days=1,\n",
    ")\n",
    "pp.process()\n",
    "\n",
    "osi.init_source_data(\n",
    "    lag_days=1,\n",
    ")\n",
    "osi.process()\n",
    "\n",
    "meta.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point the preprocessed data is ready to convert or create a configuration for the network dataset.\n",
    "\n",
    "### Dataset creation\n",
    "\n",
    "As with the `icenet_dataset_create` command we can create a dataset configuration for training the network. As before this can include cached data for the network in the format of a TFRecordDataset compatible set of tfrecords. To achieve this we create the `IceNetDataLoader`, which can both generate `IceNetDataSet` configurations (which easily provide the necessary functionality for training and prediction) as well as individual data samples for direct usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icenet.data.loaders import IceNetDataLoaderFactory\n",
    "\n",
    "implementation = \"dask\"\n",
    "loader_config = \"loader.notebook_api_pytorch_data.json\"\n",
    "dataset_name = \"notebook_api_pytorch_data\"\n",
    "lag = 1\n",
    "\n",
    "dl = IceNetDataLoaderFactory().create_data_loader(\n",
    "    implementation,\n",
    "    loader_config,\n",
    "    dataset_name,\n",
    "    lag,\n",
    "    n_forecast_days=7,\n",
    "    north=False,\n",
    "    south=True,\n",
    "    output_batch_size=1,\n",
    "    generate_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we can either use `generate` or `write_dataset_config_only` to produce a ready-to-go `IceNetDataSet` configuration. Both of these will generate a dataset config, `dataset_config.notebook_api_pytorch_data.json` (recall we set the dataset name as `notebook_api_pytorch_data` above).\n",
    "\n",
    "In this case, for pytorch, will read data in directly, rather than using cached tfrecords inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl.write_dataset_config_only()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create the IceNetDataSet object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icenet.data.dataset import IceNetDataSetPyTorch\n",
    "dataset_config = f\"dataset_config.{dataset_name}.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "shuffle = False\n",
    "persistent_workers=True\n",
    "num_workers = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train\n",
    "\n",
    "We implement a custom PyTorch class for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IceNet2 U-Net Diffusion model\n",
    "\n",
    "Maria's work (PyTorch Diffusion using U-Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Interpolate(nn.Module):\n",
    "    def __init__(self, scale_factor, mode):\n",
    "        super().__init__()\n",
    "        self.interp = F.interpolate\n",
    "        self.scale_factor = scale_factor\n",
    "        self.mode = mode\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.interp(x, scale_factor=self.scale_factor, mode=self.mode)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianDiffusion:\n",
    "    \"\"\"\n",
    "    Implements the forward and reverse processes of a Denoising Diffusion Probabilistic Model (DDPM),\n",
    "    including support for cosine and linear beta schedules.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, timesteps: int = 1000, beta_schedule: str = 'cosine'):\n",
    "        \"\"\"\n",
    "        Initialize diffusion parameters and precompute useful constants.\n",
    "\n",
    "        Args:\n",
    "            timesteps (int): Total number of diffusion steps.\n",
    "            beta_schedule (str): Type of beta schedule to use. Options: 'linear', 'cosine'.\n",
    "        \"\"\"\n",
    "        self.timesteps = timesteps\n",
    "        \n",
    "        if beta_schedule == 'linear':\n",
    "            self.betas = torch.linspace(1e-4, 0.02, timesteps)\n",
    "        elif beta_schedule == 'cosine':\n",
    "            self.betas = self._cosine_beta_schedule(timesteps)\n",
    "            \n",
    "        self.alphas = 1. - self.betas\n",
    "        self.alphas_cumprod = torch.cumprod(self.alphas, axis=0)\n",
    "        self.alphas_cumprod_prev = F.pad(self.alphas_cumprod[:-1], (1, 0), value=1.0)\n",
    "        self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod)\n",
    "        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - self.alphas_cumprod)\n",
    "        self.sqrt_recip_alphas = torch.sqrt(1.0 / self.alphas)\n",
    "        self.posterior_variance = self.betas * (1. - self.alphas_cumprod_prev) / (1. - self.alphas_cumprod)\n",
    "    \n",
    "    # def _cosine_beta_schedule(self, timesteps, s=0.008):\n",
    "    def _cosine_beta_schedule(self, timesteps, s=0.015):\n",
    "        \"\"\"\n",
    "        Compute beta schedule using a cosine function.\n",
    "\n",
    "        Args:\n",
    "            timesteps (int): Total number of timesteps.\n",
    "            s (float): Small offset to prevent singularities near 0.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Beta values of shape (timesteps,).\n",
    "        \"\"\"\n",
    "        steps = timesteps + 1\n",
    "        x = torch.linspace(0, timesteps, steps)\n",
    "        alphas_cumprod = torch.cos(((x / timesteps) + s) / (1 + s) * math.pi * 0.5) ** 2\n",
    "        alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "        betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "        \n",
    "        return torch.clip(betas, 0, 0.999)\n",
    "    \n",
    "    def q_sample(self, x_start: torch.Tensor, t: torch.Tensor, noise: torch.Tensor = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Add noise to x_start at timestep t, using the forward diffusion process.\n",
    "\n",
    "        Args:\n",
    "            x_start (torch.Tensor): Original input tensor (clean image).\n",
    "            t (torch.Tensor): Timesteps for each sample in the batch (shape: [B]).\n",
    "            noise (torch.Tensor, optional): Noise to add. If None, standard Gaussian noise is used.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Noisy sample at timestep t.\n",
    "        \"\"\"\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(x_start)\n",
    "            \n",
    "        sqrt_alphas_cumprod_t = self._extract(self.sqrt_alphas_cumprod, t, x_start.shape)\n",
    "        sqrt_one_minus_alphas_cumprod_t = self._extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape)\n",
    "        \n",
    "        return sqrt_alphas_cumprod_t * x_start + sqrt_one_minus_alphas_cumprod_t * noise\n",
    "    \n",
    "    def p_sample(self, x: torch.Tensor, t: torch.Tensor, pred_noise: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Perform a single reverse diffusion step.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Current noisy sample at timestep t.\n",
    "            t (torch.Tensor): Timesteps for each sample in the batch (shape: [B]).\n",
    "            pred_noise (torch.Tensor): Model's predicted noise (εθ) for x at timestep t.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Sample from the previous timestep (x_{t-1}).\n",
    "        \"\"\"\n",
    "        betas_t = self._extract(self.betas, t, x.shape)\n",
    "        sqrt_one_minus_alphas_cumprod_t = self._extract(self.sqrt_one_minus_alphas_cumprod, t, x.shape)\n",
    "        sqrt_recip_alphas_t = self._extract(self.sqrt_recip_alphas, t, x.shape)\n",
    "        \n",
    "        # Equation 11 in the paper (our pred_noise is εθ)\n",
    "        model_mean = sqrt_recip_alphas_t * (x - betas_t * pred_noise / sqrt_one_minus_alphas_cumprod_t)\n",
    "        \n",
    "        # Create mask for where t == 0\n",
    "        nonzero_mask = (t != 0).float().view(-1, *([1] * (len(x.shape) - 1)))\n",
    "        \n",
    "        # Only add noise if t != 0\n",
    "        posterior_variance_t = self._extract(self.posterior_variance, t, x.shape)\n",
    "        noise = torch.randn_like(x)\n",
    "        \n",
    "        return model_mean + nonzero_mask * torch.sqrt(posterior_variance_t) * noise\n",
    "\n",
    "    def _extract(self, a: torch.Tensor, t: torch.Tensor, x_shape: Tuple[int]) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Extract values from a tensor at specific timesteps t and reshape for broadcasting.\n",
    "\n",
    "        Args:\n",
    "            a (torch.Tensor): 1D tensor containing precomputed values (e.g., alpha or beta schedule).\n",
    "            t (torch.Tensor): Timesteps for each sample in the batch (shape: [B]).\n",
    "            x_shape (Tuple[int]): Target shape for broadcasting (same as input sample x).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Extracted and reshaped values for each timestep in the batch.\n",
    "        \"\"\"\n",
    "        a = a.to(t.device)\n",
    "        out = a[t]  # (batch_size,) # Reshape for broadcasting: [batch_size, 1, 1, 1, 1]\n",
    "      \n",
    "        return out.view((t.shape[0],) + (1,) * (len(x_shape) - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mc\n",
    "class UNetDiffusion(nn.Module):\n",
    "    \"\"\"\n",
    "    U-Net architecture for conditional DDPM-based forecasting.\n",
    "    Inputs include noisy predictions, time step embeddings, and conditioning inputs.\n",
    "    Supports configurable depth, filter size, and number of forecast days/classes.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_channels,\n",
    "                 filter_size=3,\n",
    "                 n_filters_factor=1,\n",
    "                 n_forecast_days=7,\n",
    "                 n_output_classes=1,\n",
    "                 timesteps=1000,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize the U-Net diffusion model.\n",
    "\n",
    "        Args:\n",
    "            input_channels (int): Number of input conditioning channels (e.g., meteorological variables).\n",
    "            filter_size (int): Convolution kernel size for all conv layers.\n",
    "            n_filters_factor (float): Scaling factor for channel depth across the network.\n",
    "            n_forecast_days (int): Number of days to forecast.\n",
    "            n_output_classes (int): Number of output regression targets per forecast day.\n",
    "            timesteps (int): Number of diffusion timesteps.\n",
    "            **kwargs: Additional arguments (ignored).\n",
    "        \"\"\"\n",
    "        super(UNetDiffusion, self).__init__()\n",
    "\n",
    "        self.input_channels = input_channels\n",
    "        self.filter_size = filter_size\n",
    "        self.n_filters_factor = n_filters_factor\n",
    "        self.n_forecast_days = n_forecast_days\n",
    "        self.n_output_classes = n_output_classes\n",
    "        self.timesteps = timesteps\n",
    "        \n",
    "        # Time embedding\n",
    "        self.time_embed_dim = 256\n",
    "        self.time_embed = nn.Sequential(\n",
    "            nn.Linear(self.time_embed_dim, self.time_embed_dim * 4),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(self.time_embed_dim * 4, self.time_embed_dim),\n",
    "        )\n",
    "        \n",
    "        # Channel calculations\n",
    "        start_out_channels = 64\n",
    "        reduced_channels = self._make_divisible(int(start_out_channels * n_filters_factor), 8)\n",
    "        channels = {\n",
    "            start_out_channels * 2**pow: self._make_divisible(reduced_channels * 2**pow, 8)\n",
    "            for pow in range(4)\n",
    "        }\n",
    "\n",
    "        self.initial_conv_channels = (n_output_classes * n_forecast_days) + input_channels\n",
    "        \n",
    "        # Encoder\n",
    "        self.conv1 = self.conv_block(self.initial_conv_channels, channels[64])\n",
    "        self.conv2 = self.conv_block(channels[64], channels[128])\n",
    "        self.conv3 = self.conv_block(channels[128], channels[256])\n",
    "        self.conv4 = self.conv_block(channels[256], channels[256])\n",
    "\n",
    "        # Bottleneck\n",
    "        self.conv5 = self.bottleneck_block(channels[256], channels[512])\n",
    "\n",
    "        # Decoder\n",
    "        self.up6 = self.upconv_block(channels[512], channels[256])\n",
    "        self.up7 = self.upconv_block(channels[256], channels[256])\n",
    "        self.up8 = self.upconv_block(channels[256], channels[128])\n",
    "        self.up9 = self.upconv_block(channels[128], channels[64])\n",
    "\n",
    "        self.up6b = self.conv_block(channels[512] + self.time_embed_dim, channels[256])\n",
    "        self.up7b = self.conv_block(channels[512] + self.time_embed_dim, channels[256])\n",
    "        self.up8b = self.conv_block(channels[256] + self.time_embed_dim, channels[128])\n",
    "        self.up9b = self.conv_block(channels[128] + self.time_embed_dim, channels[64], final=True)\n",
    "\n",
    "        # Final layer\n",
    "        self.final_layer = nn.Conv2d(channels[64], n_output_classes * n_forecast_days, kernel_size=1, padding=\"same\")\n",
    "\n",
    "    def forward(self, x, t, y, sample_weight):\n",
    "        \"\"\"\n",
    "        Forward pass of the U-Net diffusion model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Noisy forecast tensor of shape [B, H, W, n_classes, n_forecast_days].\n",
    "            t (torch.Tensor): Diffusion timestep tensor of shape [B].\n",
    "            y (torch.Tensor): Conditioning input tensor of shape [B, H, W, input_channels].\n",
    "            sample_weight (torch.Tensor or None): Optional weighting mask [B, H, W, n_classes, n_forecast_days].\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Predicted denoised forecast of shape [B, H, W, n_classes, n_forecast_days].\n",
    "        \"\"\"\n",
    "        # Time embedding\n",
    "        t = self._timestep_embedding(t)\n",
    "        t = self.time_embed(t)\n",
    "        \n",
    "        # Concatenate with conditional input\n",
    "        x = torch.cat([x, y], dim=-1)  # [b,h,w,(d*c)+input_channels]\n",
    "        \n",
    "        # Convert to channel-first format\n",
    "        x = torch.movedim(x, -1, 1)  # [b,channels,h,w]\n",
    "\n",
    "        # Encoder pathway\n",
    "        bn1 = self.conv1(x)\n",
    "        conv1 = F.max_pool2d(bn1, kernel_size=2)\n",
    "        bn2 = self.conv2(conv1)\n",
    "        conv2 = F.max_pool2d(bn2, kernel_size=2)\n",
    "        bn3 = self.conv3(conv2)\n",
    "        conv3 = F.max_pool2d(bn3, kernel_size=2)\n",
    "        bn4 = self.conv4(conv3)\n",
    "        conv4 = F.max_pool2d(bn4, kernel_size=2)\n",
    "\n",
    "        # Bottleneck\n",
    "        bn5 = self.conv5(conv4)\n",
    "\n",
    "        # Decoder with time embedding\n",
    "        up6 = self.up6(bn5)\n",
    "        up6 = torch.cat([bn4, up6], dim=1)\n",
    "        up6 = self._add_time_embedding(up6, t)\n",
    "        up6 = self.up6b(up6)\n",
    "        \n",
    "        up7 = self.up7(up6)\n",
    "        up7 = torch.cat([bn3, up7], dim=1)\n",
    "        up7 = self._add_time_embedding(up7, t)\n",
    "        up7 = self.up7b(up7)\n",
    "        \n",
    "        up8 = self.up8(up7)\n",
    "        up8 = torch.cat([bn2, up8], dim=1)\n",
    "        up8 = self._add_time_embedding(up8, t)\n",
    "        up8 = self.up8b(up8)\n",
    "        \n",
    "        up9 = self.up9(up8)\n",
    "        up9 = torch.cat([bn1, up9], dim=1)\n",
    "        up9 = self._add_time_embedding(up9, t)\n",
    "        up9 = self.up9b(up9)\n",
    "\n",
    "        # Final output\n",
    "        output = self.final_layer(up9)  # [b, c_out, h, w]\n",
    "        output = torch.movedim(output, 1, -1)  # [b, h, w, c_out]\n",
    "\n",
    "        b, h, w, c = output.shape\n",
    "        output = output.reshape((b, h, w, self.n_output_classes, self.n_forecast_days))\n",
    "\n",
    "        return output\n",
    "        \n",
    "    def _make_divisible(self, v, divisor):\n",
    "        \"\"\"\n",
    "        Ensures a value is divisible by a specified divisor.\n",
    "\n",
    "        Args:\n",
    "            v (int): Value to adjust.\n",
    "            divisor (int): Value to divide by.\n",
    "\n",
    "        Returns:\n",
    "            int: Adjusted value divisible by divisor.\n",
    "        \"\"\"\n",
    "        return max(divisor, (v // divisor) * divisor)\n",
    "\n",
    "    def _get_num_groups(self, channels):\n",
    "        \"\"\"\n",
    "        Determines the maximum number of groups that divide `channels` for GroupNorm.\n",
    "\n",
    "        Args:\n",
    "            channels (int): Number of feature channels.\n",
    "\n",
    "        Returns:\n",
    "            int: Optimal number of groups.\n",
    "        \"\"\"\n",
    "        num_groups = 8  # Start with preferred group count\n",
    "        while num_groups > 1:\n",
    "            if channels % num_groups == 0:\n",
    "                return num_groups\n",
    "            num_groups -= 1\n",
    "        return 1  # Fallback to GroupNorm(1,...) which is equivalent to LayerNorm\n",
    "\n",
    "    def _timestep_embedding(self, timesteps, dim=256, max_period=10000):\n",
    "        \"\"\"\n",
    "        Converts timestep integers into sinusoidal positional embeddings.\n",
    "\n",
    "        Args:\n",
    "            timesteps (torch.Tensor): Timestep tensor [B].\n",
    "            dim (int): Embedding dimension.\n",
    "            max_period (int): Frequency range.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Embedding tensor of shape [B, dim].\n",
    "        \"\"\"\n",
    "        half = dim // 2\n",
    "        freqs = torch.exp(\n",
    "            -math.log(max_period) * torch.arange(start=0, end=half, dtype=torch.float32) / half\n",
    "        ).to(timesteps.device)\n",
    "        args = timesteps[:, None].float() * freqs[None]\n",
    "        embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
    "        if dim % 2:\n",
    "            embedding = torch.cat([embedding, torch.zeros_like(embedding[:, :1])], dim=-1)\n",
    "        return embedding\n",
    "    \n",
    "    def _add_time_embedding(self, x, t):\n",
    "        \"\"\"\n",
    "        Concatenates time embedding across spatial dimensions.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Feature map tensor [B, C, H, W].\n",
    "            t (torch.Tensor): Time embedding tensor [B, D].\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Time-conditioned feature map [B, C+D, H, W].\n",
    "        \"\"\"\n",
    "        b, c, h, w = x.shape\n",
    "        t = t.unsqueeze(-1).unsqueeze(-1).expand(-1, -1, h, w)\n",
    "        return torch.cat([x, t], dim=1)\n",
    "    \n",
    "    def conv_block(self, in_channels, out_channels, final=False):\n",
    "        \"\"\"\n",
    "        Standard convolutional block with GroupNorm and SiLU activation.\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels.\n",
    "            out_channels (int): Number of output channels.\n",
    "            final (bool): Whether to add an extra conv layer at the end.\n",
    "\n",
    "        Returns:\n",
    "            nn.Sequential: Conv block.\n",
    "        \"\"\"\n",
    "        num_groups = self._get_num_groups(out_channels)\n",
    "        \n",
    "        layers = [\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=self.filter_size, padding=\"same\"),\n",
    "            nn.GroupNorm(num_groups, out_channels),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=self.filter_size, padding=\"same\"),\n",
    "            nn.GroupNorm(num_groups, out_channels),\n",
    "            nn.SiLU(),\n",
    "        ]\n",
    "        if not final:\n",
    "            return nn.Sequential(*layers)\n",
    "        else:\n",
    "            final_layers = [\n",
    "                nn.Conv2d(out_channels, out_channels, kernel_size=self.filter_size, padding=\"same\"),\n",
    "                nn.GroupNorm(num_groups, out_channels),\n",
    "                nn.SiLU(),\n",
    "            ]\n",
    "            return nn.Sequential(*(layers + final_layers))\n",
    "\n",
    "    def bottleneck_block(self, in_channels, out_channels):\n",
    "        \"\"\"\n",
    "        Bottleneck block at the center of the U-Net.\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): Input channel size.\n",
    "            out_channels (int): Output channel size.\n",
    "\n",
    "        Returns:\n",
    "            nn.Sequential: Bottleneck block.\n",
    "        \"\"\"\n",
    "        num_groups = self._get_num_groups(out_channels)\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=self.filter_size, padding=\"same\"),\n",
    "            nn.GroupNorm(num_groups, out_channels),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=self.filter_size, padding=\"same\"),\n",
    "            nn.GroupNorm(num_groups, out_channels),\n",
    "            nn.SiLU(),\n",
    "        )\n",
    "\n",
    "    def upconv_block(self, in_channels, out_channels):\n",
    "        \"\"\"\n",
    "        Upsampling block with interpolation and convolution.\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): Input channel size.\n",
    "            out_channels (int): Output channel size.\n",
    "\n",
    "        Returns:\n",
    "            nn.Sequential: Upsampling block.\n",
    "        \"\"\"\n",
    "        num_groups = self._get_num_groups(out_channels)\n",
    "        return nn.Sequential(\n",
    "            Interpolate(scale_factor=2, mode='nearest'),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=2, padding=\"same\"),\n",
    "            nn.GroupNorm(num_groups, out_channels),\n",
    "            nn.SiLU()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define custom metrics for use in validation and monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IceNetAccuracy(Metric):\n",
    "    \"\"\"Binary accuracy metric for use at multiple leadtimes.\n",
    "\n",
    "    Reference: https://lightning.ai/docs/torchmetrics/stable/pages/implement.html\n",
    "    \"\"\"    \n",
    "\n",
    "    # Set class properties\n",
    "    is_differentiable: bool = False\n",
    "    higher_is_better: bool = True\n",
    "    full_state_update: bool = True\n",
    "\n",
    "    def __init__(self, leadtimes_to_evaluate: list):\n",
    "        \"\"\"Custom loss/metric for binary accuracy in classifying SIC>15% for multiple leadtimes.\n",
    "\n",
    "        Args:\n",
    "            leadtimes_to_evaluate: A list of leadtimes to consider\n",
    "                e.g., [0, 1, 2, 3, 4, 5] to consider first six days in accuracy computation or\n",
    "                e.g., [0] to only look at the first day's accuracy\n",
    "                e.g., [5] to only look at the sixth day's accuracy\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.leadtimes_to_evaluate = leadtimes_to_evaluate\n",
    "        self.add_state(\"weighted_score\", default=torch.tensor(0.), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"possible_score\", default=torch.tensor(0.), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, preds: torch.Tensor, target: torch.Tensor, sample_weight: torch.Tensor):\n",
    "        # preds and target are shape (b, h, w, t)\n",
    "        preds = (preds > 0.15).long() # torch.Size([2, 432, 432, 7])\n",
    "        target = (target > 0.15).long() # torch.Size([2, 432, 432, 7])\n",
    "        \n",
    "        sample_weight = sample_weight.squeeze()\n",
    "        base_score = preds[:, :, :, self.leadtimes_to_evaluate] == target[:, :, :, self.leadtimes_to_evaluate]\n",
    "        self.weighted_score += torch.sum(base_score * sample_weight[:, :, :, self.leadtimes_to_evaluate])\n",
    "        self.possible_score += torch.sum(sample_weight[:, :, :, self.leadtimes_to_evaluate])\n",
    "\n",
    "    def compute(self):\n",
    "        return self.weighted_score.float() / self.possible_score * 100.0\n",
    "\n",
    "\n",
    "class SIEError(Metric):\n",
    "    \"\"\"\n",
    "    Sea Ice Extent error metric (in km^2) for use at multiple leadtimes.\n",
    "    \"\"\" \n",
    "\n",
    "    # Set class properties\n",
    "    is_differentiable: bool = False\n",
    "    higher_is_better: bool = False\n",
    "    full_state_update: bool = True\n",
    "\n",
    "    def __init__(self, leadtimes_to_evaluate: list):\n",
    "        \"\"\"Construct an SIE error metric (in km^2) for use at multiple leadtimes.\n",
    "            leadtimes_to_evaluate: A list of leadtimes to consider\n",
    "                e.g., [0, 1, 2, 3, 4, 5] to consider six days in computation or\n",
    "                e.g., [0] to only look at the first day\n",
    "                e.g., [5] to only look at the sixth day\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.leadtimes_to_evaluate = leadtimes_to_evaluate\n",
    "        self.add_state(\"pred_sie\", default=torch.tensor(0.), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"true_sie\", default=torch.tensor(0.), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, preds: torch.Tensor, target: torch.Tensor, sample_weight: torch.Tensor):\n",
    "        # preds and target are shape (b, h, w, t)\n",
    "        preds = (preds > 0.15).long()\n",
    "        target = (target > 0.15).long()\n",
    "        self.pred_sie += preds[:, :, :, self.leadtimes_to_evaluate].sum()\n",
    "        self.true_sie += target[:, :, :, self.leadtimes_to_evaluate].sum()\n",
    "\n",
    "    def compute(self):\n",
    "        return (self.pred_sie - self.true_sie) * 25**2 # each pixel is 25x25 km"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define custom loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedBCEWithLogitsLoss(nn.BCEWithLogitsLoss):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def forward(self, inputs, targets, sample_weights):\n",
    "        \"\"\"\n",
    "        Weighted BCEWithLogitsLoss loss.\n",
    "\n",
    "        Compute BCEWithLogitsLoss loss weighted by masking.\n",
    "\n",
    "        Using BCEWithLogitsLoss instead of BCELoss, as pytorch docs mentions it is\n",
    "        more numerically stable.\n",
    "        https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html\n",
    "        \n",
    "        \"\"\"\n",
    "        # Computing using nn.BCEWithLogitsLoss base class. This class must be instantiated via:\n",
    "        # >>> criterion = WeightedBCEWithLogitsLoss(reduction='none')\n",
    "        loss = super().forward(\n",
    "                            (inputs.movedim(-2, 1)),\n",
    "                            (targets.movedim(-1, 1))\n",
    "                         )*sample_weights.movedim(-1, 1)\n",
    "        \n",
    "        return loss.mean()\n",
    "\n",
    "class WeightedL1Loss(nn.L1Loss):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def forward(self, inputs, targets, sample_weights):\n",
    "        \"\"\"\n",
    "        Weighted L1 loss.\n",
    "\n",
    "        Compute L1 loss weighted by masking.\n",
    "        \n",
    "        \"\"\"\n",
    "        y_hat = torch.sigmoid(inputs)\n",
    "\n",
    "        loss = super().forward(\n",
    "                            (100*y_hat), \n",
    "                            (100*targets)\n",
    "                         )*sample_weights\n",
    "        \n",
    "        return loss.mean()\n",
    "\n",
    "class WeightedMSELoss(nn.MSELoss):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def forward(self, inputs, targets, sample_weights):\n",
    "        \"\"\"\n",
    "        Weighted MSE loss.\n",
    "\n",
    "        Compute MSE loss weighted by masking.\n",
    "        \n",
    "        \"\"\"\n",
    "        y_hat = inputs\n",
    "        y_hat = y_hat.squeeze()\n",
    "        targets = targets.squeeze()\n",
    "\n",
    "        sample_weights = sample_weights.squeeze()\n",
    "        loss = super().forward((100*y_hat), (100*targets))*sample_weights\n",
    "        \n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A _LightningModule_ wrapper for UNetDiffusion model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for training UNetDiffusion model using PyTorch Lightning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mc\n",
    "\n",
    "class LitDiffusion(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    PyTorch Lightning wrapper for training and evaluating a diffusion-based model\n",
    "    (e.g., DDPM) for conditional forecasting. Handles training loop, sampling, \n",
    "    metrics, and optimizer configuration.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 model: nn.Module,\n",
    "                 learning_rate: float,\n",
    "                 criterion: callable,\n",
    "                 timesteps: int = 1000):\n",
    "        \"\"\"\n",
    "        Initialize the LightningModule for DDPM training.\n",
    "\n",
    "        Args:\n",
    "            model (nn.Module): The U-Net-style diffusion model.\n",
    "            learning_rate (float): Optimizer learning rate.\n",
    "            criterion (callable): Loss function used for evaluation (e.g., WeightedBCE or WeightedMSE).\n",
    "            timesteps (int): Number of diffusion steps (T).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.timesteps = timesteps\n",
    "        self.diffusion = GaussianDiffusion(timesteps=timesteps)\n",
    "        self.criterion = criterion\n",
    "        \n",
    "        self.n_output_classes = model.n_output_classes\n",
    "\n",
    "        metrics = {\n",
    "            \"val_accuracy\": IceNetAccuracy(leadtimes_to_evaluate=list(range(self.model.n_forecast_days))),\n",
    "            \"val_sieerror\": SIEError(leadtimes_to_evaluate=list(range(self.model.n_forecast_days)))\n",
    "        }\n",
    "        for i in range(self.model.n_forecast_days):\n",
    "            metrics[f\"val_accuracy_{i}\"] = IceNetAccuracy(leadtimes_to_evaluate=[i])\n",
    "            metrics[f\"val_sieerror_{i}\"] = SIEError(leadtimes_to_evaluate=[i])\n",
    "        self.metrics = MetricCollection(metrics)\n",
    "\n",
    "        test_metrics = {\n",
    "            \"test_accuracy\": IceNetAccuracy(leadtimes_to_evaluate=list(range(self.model.n_forecast_days))),\n",
    "            \"test_sieerror\": SIEError(leadtimes_to_evaluate=list(range(self.model.n_forecast_days)))\n",
    "        }\n",
    "        for i in range(self.model.n_forecast_days):\n",
    "            test_metrics[f\"test_accuracy_{i}\"] = IceNetAccuracy(leadtimes_to_evaluate=[i])\n",
    "            test_metrics[f\"test_sieerror_{i}\"] = SIEError(leadtimes_to_evaluate=[i])\n",
    "        self.test_metrics = MetricCollection(test_metrics)\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Run the model in inference mode.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor or tuple): Either a tensor [B, H, W, C] or a batch from DataLoader.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Generated sample(s).\n",
    "        \"\"\"\n",
    "        if isinstance(x, (list, tuple)):\n",
    "            x = x[0]  # Extract input features from batch tuple\n",
    "        elif not isinstance(x, torch.Tensor):\n",
    "            x = torch.tensor(x, device=self.device)\n",
    "        return self.sample(x)\n",
    "\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        \"\"\"\n",
    "        One training step using DDPM loss (predicted noise vs. true noise).\n",
    "\n",
    "        Args:\n",
    "            batch (tuple): (x, y, sample_weight).\n",
    "\n",
    "        Returns:\n",
    "            dict: {\"loss\": loss}\n",
    "        \"\"\"\n",
    "        x, y, sample_weight = batch\n",
    "        y = y.squeeze(-1)  # Removes the last dimension (size 1)\n",
    "        \n",
    "        # Sample random timesteps\n",
    "        t = torch.randint(0, self.timesteps, (x.shape[0],), device=x.device).long()\n",
    "        \n",
    "        # Create noisy version\n",
    "        noise = torch.randn_like(y)\n",
    "        noisy_y = self.diffusion.q_sample(y, t, noise)\n",
    "        \n",
    "        # Predict the noise\n",
    "        pred_noise = self.model(noisy_y, t, x, sample_weight)\n",
    "        \n",
    "        pred_noise = pred_noise.squeeze()\n",
    "        noise = noise.squeeze()\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = F.mse_loss(pred_noise, noise) #, reduction='none')  \n",
    "\n",
    "        # print(f\"loss: {loss.shape}\")  # Should be [B,H,W,432]\n",
    "        # print(f\"sample_weight: {sample_weight.shape}\")  # Likely [B,H,W,7,1]\n",
    "        \n",
    "        # # Apply sample weights\n",
    "        # if sample_weight is not None:\n",
    "        #     # Ensure proper broadcasting: [B,H,W,1] -> [B,H,W,C]\n",
    "        #     loss = loss * sample_weight.squeeze(-1)\n",
    "        \n",
    "        # # Final reduction\n",
    "        # noise_loss = loss.mean()  # Scalar value\n",
    "        \n",
    "        # outputs = self.sample(x, sample_weight)\n",
    "        # y_hat = torch.sigmoid(outputs)\n",
    "        # pred_loss = self.criterion(y_hat, y, sample_weight)\n",
    "\n",
    "        # alpha = 0.5\n",
    "        # loss = (alpha * noise_loss) + ((1 - alpha) * pred_loss)\n",
    "        \n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, sync_dist=True)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        \"\"\"\n",
    "        One validation step using structural loss.\n",
    "\n",
    "        Args:\n",
    "            batch (tuple): (x, y, sample_weight)\n",
    "\n",
    "        Returns:\n",
    "            dict: {\"val_loss\": loss}\n",
    "        \"\"\"\n",
    "        x, y, sample_weight = batch\n",
    "        y = y.squeeze(-1)  # Removes the last dimension (size 1)\n",
    "        \n",
    "        outputs = self.sample(x, sample_weight)\n",
    "        y_hat = torch.sigmoid(outputs)\n",
    "\n",
    "        loss = self.criterion(y_hat, y, sample_weight)\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, sync_dist=True)  # epoch-level loss\n",
    "\n",
    "        self.metrics.update(y_hat, y, sample_weight)  \n",
    "        return {\"val_loss\": loss}\n",
    "\n",
    "    def sample(self, x, sample_weight, num_samples=1):\n",
    "        \"\"\"\n",
    "        Perform reverse diffusion sampling starting from noise.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Conditioning input [B, H, W, C].\n",
    "            sample_weight (torch.Tensor or None): Optional weights.\n",
    "            num_samples (int): Not used (for future batching).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Final denoised output [B, H, W, C_out].\n",
    "        \"\"\"\n",
    "        shape = (x.shape[0], *x.shape[1:-1], self.model.n_forecast_days * self.n_output_classes)\n",
    "        device = x.device\n",
    "        \n",
    "        # Start from pure noise\n",
    "        y = torch.randn(shape, device=device)\n",
    "        \n",
    "        for t in reversed(range(0, self.timesteps)):\n",
    "            t_batch = torch.full((x.shape[0],), t, device=device, dtype=torch.long)\n",
    "            pred_noise = self.model(y, t_batch, x, sample_weight)\n",
    "        \n",
    "            pred_noise = pred_noise.squeeze(3)\n",
    "            y = self.diffusion.p_sample(y, t_batch, pred_noise)\n",
    "            \n",
    "        return y\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        \"\"\"\n",
    "        Called at the end of validation to log all collected metrics.\n",
    "        \"\"\"\n",
    "        self.log_dict(self.metrics.compute(), on_step=False, on_epoch=True, prog_bar=True, sync_dist=True)\n",
    "        self.metrics.reset()\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        One test step using structural loss and full metric evaluation.\n",
    "\n",
    "        Args:\n",
    "            batch (tuple): (x, y, sample_weight)\n",
    "            batch_idx (int): Batch index.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Loss value.\n",
    "        \"\"\"\n",
    "        x, y, sample_weight = batch\n",
    "        y = y.squeeze(-1)  # Removes the last dimension (size 1)\n",
    "        \n",
    "        outputs = self.sample(x, sample_weight)\n",
    "        y_hat = torch.sigmoid(outputs)\n",
    "        loss = self.criterion(y_hat, y, sample_weight)\n",
    "        \n",
    "        self.log(\"test_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, sync_dist=True)  # epoch-level loss\n",
    "        self.test_metrics.update(y_hat, y, sample_weight)\n",
    "    \n",
    "        return loss\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        \"\"\"\n",
    "        Called at the end of test loop to log all collected metrics.\n",
    "        \"\"\"\n",
    "        self.log_dict(self.test_metrics.compute(), on_step=False, on_epoch=True, sync_dist=True)\n",
    "        self.test_metrics.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        Set up the optimizer.\n",
    "\n",
    "        Returns:\n",
    "            torch.optim.Optimizer: Adam optimizer.\n",
    "        \"\"\"\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "        \n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        \"\"\"\n",
    "        Perform prediction on a single batch.\n",
    "\n",
    "        Args:\n",
    "            batch (tuple): (x, y, sample_weight).\n",
    "            batch_idx (int): Batch index.\n",
    "            dataloader_idx (int): Index of the DataLoader (if using multiple).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Prediction tensor [B, H, W, C_out].\n",
    "        \"\"\"\n",
    "        x, y, sample_weight = batch\n",
    "        y = y.squeeze(-1)  # Removes the last dimension (size 1)\n",
    "        \n",
    "        outputs = self.sample(x, sample_weight)\n",
    "        y_hat = torch.sigmoid(outputs)\n",
    "            \n",
    "        loss = self.criterion(y_hat, y, sample_weight)\n",
    "\n",
    "        return y_hat\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "def train_diffusion_icenet(configuration_path,\n",
    "                          learning_rate,\n",
    "                          max_epochs,\n",
    "                          batch_size,\n",
    "                          n_workers,\n",
    "                          filter_size,\n",
    "                          n_filters_factor,\n",
    "                          seed,\n",
    "                          timesteps=1000):\n",
    "    \"\"\"\n",
    "    Train IceNet diffusion model using the specified parameters.\n",
    "\n",
    "    Args:\n",
    "        configuration_path (str): Path to IceNet configuration YAML file.\n",
    "        learning_rate (float): Learning rate for optimizer.\n",
    "        max_epochs (int): Number of training epochs.\n",
    "        batch_size (int): Mini-batch size.\n",
    "        n_workers (int): Number of workers for data loading.\n",
    "        filter_size (int): Convolution kernel size used in UNet layers.\n",
    "        n_filters_factor (float): Scaling factor for number of filters in UNet.\n",
    "        seed (int): Random seed for reproducibility.\n",
    "        timesteps (int): Number of diffusion steps (T).\n",
    "\n",
    "    Returns:\n",
    "        tuple: (model, trainer, checkpoint_callback)\n",
    "            model (UNetDiffusion): Trained model.\n",
    "            trainer (pl.Trainer): PyTorch Lightning trainer used for training.\n",
    "            checkpoint_callback (ModelCheckpoint): Callback used for saving the best model.\n",
    "    \"\"\"\n",
    "    # init\n",
    "    pl.seed_everything(seed)\n",
    "    \n",
    "    # configure datasets and dataloaders\n",
    "    train_dataset = IceNetDataSetPyTorch(configuration_path, mode=\"train\")\n",
    "    val_dataset = IceNetDataSetPyTorch(configuration_path, mode=\"val\")\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, num_workers=n_workers,\n",
    "                                 persistent_workers=persistent_workers, shuffle=False)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, num_workers=n_workers,\n",
    "                               persistent_workers=persistent_workers, shuffle=False)\n",
    "\n",
    "    #mc debug\n",
    "    # Check the shape of a batch of data from the train dataloader\n",
    "    for batch in train_dataloader:\n",
    "        # Assuming the batch contains (x, y, sample_weight)\n",
    "        x, y, sample_weight = batch\n",
    "        break  # We only need to inspect one batch\n",
    "\n",
    "    # construct diffusion model\n",
    "    model = UNetDiffusion(\n",
    "        input_channels=train_dataset._num_channels,\n",
    "        filter_size=filter_size,\n",
    "        n_filters_factor=n_filters_factor,\n",
    "        n_forecast_days=train_dataset._n_forecast_days,\n",
    "        timesteps=timesteps\n",
    "    )\n",
    "    \n",
    "    criterion = WeightedMSELoss(reduction=\"none\")\n",
    "    \n",
    "    # configure PyTorch Lightning module\n",
    "    lit_module = LitDiffusion(\n",
    "        model=model,\n",
    "        learning_rate=learning_rate,\n",
    "        criterion=criterion,\n",
    "        timesteps=timesteps\n",
    "    )\n",
    "\n",
    "    # set up trainer configuration\n",
    "    trainer = pl.Trainer(\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        log_every_n_steps=5,\n",
    "        max_epochs=max_epochs,\n",
    "        num_sanity_val_steps=1,\n",
    "        fast_dev_run=False,\n",
    "    )\n",
    "    # checkpoint_callback = ModelCheckpoint(monitor=\"val_loss\", mode=\"min\")\n",
    "    checkpoint_callback = ModelCheckpoint(monitor=\"val_accuracy\", mode=\"max\")\n",
    "    trainer.callbacks.append(checkpoint_callback)\n",
    "\n",
    "    # train model\n",
    "    print(f\"Training {len(train_dataset)} examples / {len(train_dataloader)} batches (batch size {batch_size}).\")\n",
    "    print(f\"Validating {len(val_dataset)} examples / {len(val_dataloader)} batches (batch size {batch_size}).\")\n",
    "    trainer.fit(lit_module, train_dataloader, val_dataloader)\n",
    "\n",
    "    return model, trainer, checkpoint_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "seed = 45\n",
    "\n",
    "#mc\n",
    "model, trainer, checkpoint_callback = train_diffusion_icenet(\n",
    "    configuration_path=dataset_config,\n",
    "    learning_rate=3e-4, #3e-4, #1e-4,\n",
    "    max_epochs=150,\n",
    "    batch_size=batch_size,\n",
    "    n_workers=num_workers,\n",
    "    filter_size=3,\n",
    "    n_filters_factor=0.5, #0.7, #1.0, #0.4,\n",
    "    seed=seed,\n",
    "    timesteps=1000\n",
    ")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conduct actual training run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 45\n",
    "\n",
    "#mc\n",
    "model, trainer, checkpoint_callback = train_diffusion_icenet(\n",
    "    configuration_path=dataset_config,\n",
    "    learning_rate=3e-4, #3e-4, #1e-4,\n",
    "    max_epochs=150,\n",
    "    batch_size=batch_size,\n",
    "    n_workers=num_workers,\n",
    "    filter_size=3,\n",
    "    n_filters_factor=0.5, #0.7, #1.0, #0.4,\n",
    "    seed=seed,\n",
    "    timesteps=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicts using the best checkpoint from the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback.best_k_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_checkpoint = checkpoint_callback.best_model_path\n",
    "best_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best result from the checkpoint\n",
    "# best_model = LitUNet.load_from_checkpoint(best_checkpoint)\n",
    "\n",
    "#mc\n",
    "best_model = LitDiffusion.load_from_checkpoint(best_checkpoint)\n",
    "\n",
    "# disable randomness, dropout, etc...\n",
    "best_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = IceNetDataSetPyTorch(configuration_path=dataset_config, mode=\"test\")\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers,\n",
    "                             persistent_workers=persistent_workers, shuffle=False)\n",
    "\n",
    "# automatically load the best weights (if best_model isn't added)\n",
    "trainer.test(dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cosine results\n",
    "# [{'test_loss': 0.48640450835227966,\n",
    "#   'test_accuracy': 51.62199783325195,\n",
    "#   'test_accuracy_0': 51.56485366821289,\n",
    "#   'test_accuracy_1': 51.77238464355469,\n",
    "#   'test_accuracy_2': 52.235984802246094,\n",
    "#   'test_accuracy_3': 51.62677764892578,\n",
    "#   'test_accuracy_4': 51.081172943115234,\n",
    "#   'test_accuracy_5': 51.31882858276367,\n",
    "#   'test_accuracy_6': 51.75397872924805,\n",
    "#   'test_sieerror': 729145600.0,\n",
    "#   'test_sieerror_0': 104656872.0,\n",
    "#   'test_sieerror_1': 104813752.0,\n",
    "#   'test_sieerror_2': 104287504.0,\n",
    "#   'test_sieerror_3': 104360624.0,\n",
    "#   'test_sieerror_4': 104103128.0,\n",
    "#   'test_sieerror_5': 103494376.0,\n",
    "#   'test_sieerror_6': 103429376.0}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Generating predictions\")\n",
    "\n",
    "predictions = trainer.predict(best_model, dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for worker, prediction in enumerate(predictions):\n",
    "    print(f\"Worker: {worker} | Prediction: {prediction.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Outputs and Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create prediction output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = \"pytorch_notebook\"\n",
    "network_name = \"api_pytorch_dataset\"\n",
    "output_name = \"example_pytorch_forecast_diff\"\n",
    "output_folder = os.path.join(\".\", \"results\", \"predict\", output_name,\n",
    "                                \"{}.{}\".format(network_name, seed))\n",
    "os.makedirs(output_folder, exist_ok=output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert and output predictions to numpy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "for workers, prediction in enumerate(predictions):\n",
    "    for batch in range(prediction.shape[0]):\n",
    "        date = pd.Timestamp(test_dataset.dates[idx].replace('_', '-'))\n",
    "        output_path = os.path.join(output_folder, date.strftime(\"%Y_%m_%d.npy\"))\n",
    "        print(\"prediction shape...\",prediction.shape)\n",
    "        # forecast = prediction[batch, :, :, :, :].movedim(-2, 0)\n",
    "        forecast = prediction[batch, :, :, :].movedim(-1, 0)\n",
    "        forecast_np = forecast.detach().cpu().numpy()\n",
    "        np.save(output_path, forecast_np)\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a csv file with all the test dates we have predicted for, and to use in generating the final netCDF output using `icenet_output`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!printf \"2020-04-01\\n2020-04-02\" | tee testdates_diff.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!icenet_output -m -o results/predict example_pytorch_forecast_diff notebook_api_pytorch_data testdates_diff.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Change this to the actual version dir\n",
    "log_dir = \"lightning_logs/version_1062817\"\n",
    "# log_dir = f\"lightning_logs/version_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "\n",
    "# Load the logs\n",
    "event_acc = EventAccumulator(log_dir)\n",
    "event_acc.Reload()\n",
    "\n",
    "# List all scalar tags to find the correct name\n",
    "print(\"Available tags:\", event_acc.Tags()['scalars'])\n",
    "\n",
    "# Get the scalar events for val_loss\n",
    "val_loss_events = event_acc.Scalars('val_loss')\n",
    "\n",
    "# FIX: Use index as epoch number instead of .step\n",
    "steps = list(range(1, len(val_loss_events) + 1))\n",
    "values = [e.value for e in val_loss_events]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(steps, values, label='Validation Loss', color='blue')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Validation Loss\")\n",
    "plt.title(\"Validation Loss Over Training\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update with your actual path\n",
    "log_dir = \"lightning_logs/version_1062817\"\n",
    "# log_dir = f\"lightning_logs/version_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "\n",
    "event_acc = EventAccumulator(log_dir)\n",
    "event_acc.Reload()\n",
    "\n",
    "# List all available scalar tags\n",
    "print(\"Available scalar tags:\")\n",
    "print(event_acc.Tags()['scalars'])  # e.g. val_accuracy, val_accuracy_0, etc.\n",
    "\n",
    "# Get accuracy for all lead times (overall accuracy)\n",
    "accuracy_events = event_acc.Scalars('val_accuracy')\n",
    "\n",
    "# FIX: Use index as epoch number instead of .step\n",
    "steps = list(range(1, len(accuracy_events) + 1))\n",
    "values = [e.value for e in accuracy_events]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(steps, values, label='Validation Accuracy', color='green')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Validation Accuracy Over Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import datetime as dt\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icenet.plotting.video import xarray_to_video as xvid\n",
    "from icenet.data.sic.mask import Masks\n",
    "\n",
    "ds = xr.open_dataset(\"results/predict/example_pytorch_forecast_diff.nc\")\n",
    "land_mask = Masks(south=True, north=False).get_land_mask()\n",
    "ds.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Animate result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_date = ds.time.values[0]\n",
    "fc = ds.sic_mean.isel(time=0).drop_vars(\"time\").rename(dict(leadtime=\"time\"))\n",
    "fc['time'] = [pd.to_datetime(forecast_date) \\\n",
    "              + dt.timedelta(days=int(e)) for e in fc.time.values]\n",
    "\n",
    "anim = xvid(fc, 15, figsize=(4,4), mask=land_mask)\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check min/max of predicted SIC fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( forecast_np[:, :, :, 0].shape )\n",
    "fmin, fmax = np.min(forecast_np[:, :, :, 0]), np.max(forecast_np[:, :, :, 0])\n",
    "print( f\"First forecast day min: {fmin:.4f}, max: {fmax:.4f}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load original input dataset\n",
    "\n",
    "This is the original input dataset (pre-normalisation) for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original input dataset (domain not normalised)\n",
    "xr.plot.contourf(xr.open_dataset(\"data/osisaf/south/siconca/2020.nc\").isel(time=92).ice_conc, levels=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version\n",
    "- IceNet Codebase: v0.2.8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seaice_env2 (Conda)",
   "language": "python",
   "name": "sys_seaice_env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
